{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bill/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "random = np.random.random\n",
    "randn = np.random.randn\n",
    "Dataset = tf.data.Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# baisc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.62434536, -0.61175641],\n",
       "       [-0.52817175, -1.07296862]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_seed = 1\n",
    "np.random.seed(_seed)\n",
    "array = np.random.randn(2,2)\n",
    "array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  \n",
    "- convert_to_tensor\n",
    "- from_tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "_X = [tf.convert_to_tensor(randn(2,2)) for _ in range(10)]\n",
    "X = Dataset.from_tensor_slices(tf.stack(_X))\n",
    "_y = [tf.convert_to_tensor(random()) for _ in range(10)]\n",
    "y = Dataset.from_tensor_slices(tf.stack(_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ZipDataset shapes: ((2, 2), ()), types: (tf.float64, tf.float32)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# zip\n",
    "dataset = Dataset.zip((X,y))\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_datasets': (<TensorSliceDataset shapes: (2, 2), types: tf.float64>,\n",
       "  <TensorSliceDataset shapes: (), types: tf.float32>)}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.__dict__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## batching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((?, 2, 2), (?,)), types: (tf.float64, tf.float32)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batched_dataset = dataset.batch(4)\n",
    "batched_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "batching 只是添加了另外一个dim维度"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## repeat and shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ShuffleDataset shapes: ((2, 2), ()), types: (tf.float64, tf.float32)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buffer_size = 2\n",
    "n_dataset = dataset.repeat(2).shuffle(buffer_size)\n",
    "n_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ZipDataset shapes: ((2, 2), ()), types: (tf.float64, tf.float32)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# iterator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### one shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "_iter = n_dataset.make_one_shot_iterator()\n",
    "a = _iter.get_next()\n",
    "with tf.Session() as sess:\n",
    "    N = 0\n",
    "    while True:\n",
    "        try:\n",
    "#             print(N)\n",
    "            sess.run(a)\n",
    "            N += 1\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### initializable: dataset initialization  \n",
    "dataset是同一个  \n",
    "iterator must be initialized before using it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "_iter = n_dataset.make_initializable_iterator()\n",
    "_iter.initializer\n",
    "e = _iter.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([[ 0.3190391 , -0.24937038],\n",
      "       [ 1.46210794, -2.06014071]]), 0.5358964)\n",
      "(array([[-0.3224172 , -0.38405435],\n",
      "       [ 1.13376944, -1.09989127]]), 0.66379464)\n",
      "(array([[-0.17242821, -0.87785842],\n",
      "       [ 0.04221375,  0.58281521]]), 0.5148891)\n",
      "(array([[-1.10061918,  1.14472371],\n",
      "       [ 0.90159072,  0.50249434]]), 0.94459474)\n",
      "(array([[ 0.90085595, -0.68372786],\n",
      "       [-0.12289023, -0.93576943]]), 0.58655506)\n",
      "(array([[-0.26788808,  0.53035547],\n",
      "       [-0.69166075, -0.39675353]]), 0.9034019)\n",
      "(array([[-0.6871727 , -0.84520564],\n",
      "       [-0.67124613, -0.0126646 ]]), 0.1374747)\n",
      "(array([[ 0.86540763, -2.3015387 ],\n",
      "       [ 1.74481176, -0.7612069 ]]), 0.04995346)\n",
      "(array([[-1.11731035,  0.2344157 ],\n",
      "       [ 1.65980218,  0.74204416]]), 0.13927634)\n",
      "(array([[ 0.86540763, -2.3015387 ],\n",
      "       [ 1.74481176, -0.7612069 ]]), 0.04995346)\n",
      "(array([[ 0.3190391 , -0.24937038],\n",
      "       [ 1.46210794, -2.06014071]]), 0.5358964)\n",
      "(array([[-0.19183555, -0.88762896],\n",
      "       [-0.74715829,  1.6924546 ]]), 0.8073913)\n",
      "(array([[-0.3224172 , -0.38405435],\n",
      "       [ 1.13376944, -1.09989127]]), 0.66379464)\n",
      "(array([[-1.10061918,  1.14472371],\n",
      "       [ 0.90159072,  0.50249434]]), 0.94459474)\n",
      "(array([[-0.17242821, -0.87785842],\n",
      "       [ 0.04221375,  0.58281521]]), 0.5148891)\n",
      "(array([[-0.26788808,  0.53035547],\n",
      "       [-0.69166075, -0.39675353]]), 0.9034019)\n",
      "(array([[-0.6871727 , -0.84520564],\n",
      "       [-0.67124613, -0.0126646 ]]), 0.1374747)\n",
      "(array([[-1.11731035,  0.2344157 ],\n",
      "       [ 1.65980218,  0.74204416]]), 0.13927634)\n",
      "(array([[ 0.90085595, -0.68372786],\n",
      "       [-0.12289023, -0.93576943]]), 0.58655506)\n",
      "(array([[-0.19183555, -0.88762896],\n",
      "       [-0.74715829,  1.6924546 ]]), 0.8073913)\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(_iter.initializer)\n",
    "    while True:\n",
    "        try:\n",
    "            print(sess.run(e))\n",
    "        except:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reinitializable\n",
    "iterator initialization\n",
    "iterator 是同一个， dataset可以不同  \n",
    "- Iterator.from_structure(output_types, output_shapes)\n",
    "- make_initializer(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "dataset1 = Dataset.range(2,8,3)\n",
    "dataset2 = Dataset.range(1,5,2)\n",
    "Iterator = tf.data.Iterator\n",
    "_iter = Iterator.from_structure(dataset1.output_types, dataset1.output_shapes)\n",
    "e = _iter.get_next()\n",
    "init1 = _iter.make_initializer(dataset1)\n",
    "init2 = _iter.make_initializer(dataset2)\n",
    "sess = tf.Session()\n",
    "sess.run(init1)\n",
    "print(sess.run(e))\n",
    "sess.run(init2)\n",
    "print(sess.run(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### feedable\n",
    "like generator: does not require you to initialize the iterator from the start of a dataset when you switch between iterators  \n",
    "- resume state: using handle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "5\n",
      "8\n",
      "23\n",
      "26\n",
      "29\n",
      "11\n",
      "14\n",
      "17\n",
      "23\n",
      "26\n",
      "29\n",
      "2\n",
      "5\n",
      "8\n",
      "23\n",
      "26\n",
      "29\n",
      "11\n",
      "14\n",
      "17\n",
      "23\n",
      "26\n",
      "29\n",
      "2\n",
      "5\n",
      "8\n",
      "23\n",
      "26\n",
      "29\n",
      "11\n",
      "14\n",
      "17\n",
      "23\n",
      "26\n",
      "29\n",
      "2\n",
      "5\n",
      "8\n",
      "23\n",
      "26\n",
      "29\n",
      "11\n",
      "14\n",
      "17\n",
      "23\n",
      "26\n",
      "29\n",
      "2\n",
      "5\n",
      "8\n",
      "23\n",
      "26\n",
      "29\n",
      "11\n",
      "14\n",
      "17\n",
      "23\n",
      "26\n",
      "29\n",
      "2\n",
      "5\n",
      "8\n",
      "23\n",
      "26\n",
      "29\n",
      "11\n",
      "14\n",
      "17\n",
      "23\n",
      "26\n",
      "29\n",
      "2\n",
      "5\n",
      "8\n",
      "23\n",
      "26\n",
      "29\n",
      "11\n",
      "14\n",
      "17\n",
      "23\n",
      "26\n",
      "29\n",
      "2\n",
      "5\n",
      "8\n",
      "23\n",
      "26\n",
      "29\n",
      "11\n",
      "14\n",
      "17\n",
      "23\n",
      "26\n",
      "29\n",
      "2\n",
      "5\n",
      "8\n",
      "23\n",
      "26\n",
      "29\n",
      "11\n",
      "14\n",
      "17\n",
      "23\n",
      "26\n",
      "29\n",
      "2\n",
      "5\n",
      "8\n",
      "23\n",
      "26\n",
      "29\n",
      "11\n",
      "14\n",
      "17\n",
      "23\n",
      "26\n",
      "29\n"
     ]
    }
   ],
   "source": [
    "iter1 = Dataset.range(2, 20, 3).repeat().make_one_shot_iterator()\n",
    "iter2 = Dataset.range(23, 40, 3).make_initializable_iterator()\n",
    "\n",
    "handle = tf.placeholder(tf.string, shape=[], name='handle')\n",
    "_iter1 = Iterator.from_string_handle(handle, dataset1.output_types, dataset1.output_shapes)\n",
    "e = _iter1.get_next()\n",
    "sess = tf.Session()\n",
    "h1, h2 = sess.run((iter1.string_handle(),iter2.string_handle()))\n",
    "\n",
    "for _ in range(20):\n",
    "    for _ in range(3):\n",
    "        print(sess.run(e, feed_dict={handle: h1}))\n",
    "\n",
    "    sess.run(iter2.initializer)\n",
    "    for _ in range(3):\n",
    "        print(sess.run(e, feed_dict={handle: h2}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## ptb Dataset API\n",
    "- convert_to_tensor  \n",
    "- size\n",
    "- Dataset.range(start, stop, step)\n",
    "- set_shape(shape_tuple)\n",
    "- dataset.batch(batch_size)\n",
    "- make_one_shot_iterator()\n",
    "- iterator.get_next()\n",
    "- dataset.map(_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor 'IteratorGetNext_4:0' shape=(?, 2) dtype=int32>, <tf.Tensor 'IteratorGetNext_4:1' shape=(?, 2) dtype=int32>)\n"
     ]
    }
   ],
   "source": [
    "# ptb laguage data\n",
    "batch_size = 2\n",
    "num_steps = 2\n",
    "raw_data = tf.convert_to_tensor(list(range(20)))\n",
    "data_len = tf.size(raw_data)\n",
    "raw_data = raw_data[0: data_len//num_steps * num_steps]\n",
    "data_len = tf.size(raw_data)\n",
    "_sample_begins = Dataset.range(0, tf.cast(data_len - 1, tf.int64), num_steps)\n",
    "\n",
    "def _xy(i):\n",
    "    \"a element\"\n",
    "    x = raw_data[i: i+num_steps]\n",
    "    x.set_shape((num_steps))\n",
    "    y = raw_data[i+1: i+num_steps+1]\n",
    "    y.set_shape((num_steps))\n",
    "    return x, y\n",
    "buffer_size = 100\n",
    "with tf.Session().as_default():\n",
    "    print(_sample_begins.repeat(2)\n",
    "                        .shuffle(buffer_size)\n",
    "                        .map(_xy)\n",
    "                        .batch(batch_size)\n",
    "                        .make_one_shot_iterator()\n",
    "                        .get_next())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
